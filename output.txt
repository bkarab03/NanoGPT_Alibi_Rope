encoding alibi iter 0: loss 4.1673%
encoding alibi iter 20: loss 3.4348%
encoding alibi iter 40: loss 3.0127%
encoding alibi iter 60: loss 2.6848%
encoding alibi iter 80: loss 2.6191%
encoding alibi iter 100: loss 2.5488%
encoding alibi iter 120: loss 2.5799%
encoding alibi iter 140: loss 2.5507%
encoding alibi iter 160: loss 2.5091%
encoding alibi iter 180: loss 2.4953%
encoding alibi iter 200: loss 2.4615%
encoding alibi iter 220: loss 2.5373%
encoding alibi iter 240: loss 2.4538%
encoding alibi iter 260: loss 2.4144%
encoding alibi iter 280: loss 2.4209%
encoding alibi iter 300: loss 2.3910%
encoding alibi iter 320: loss 2.4432%
encoding alibi iter 340: loss 2.3881%
encoding alibi iter 360: loss 2.4018%
encoding alibi iter 380: loss 2.3505%
encoding alibi iter 400: loss 2.3536%
encoding alibi iter 420: loss 2.3798%
encoding alibi iter 440: loss 2.3187%
encoding alibi iter 460: loss 2.3770%
encoding alibi iter 480: loss 2.3937%
encoding alibi iter 500: loss 2.3739%
encoding alibi iter 520: loss 2.2550%
encoding alibi iter 540: loss 2.3122%
encoding alibi iter 560: loss 2.3423%
encoding alibi iter 580: loss 2.2989%
encoding alibi iter 600: loss 2.2447%
encoding alibi iter 620: loss 2.2889%
encoding alibi iter 640: loss 2.2779%
encoding alibi iter 660: loss 2.2783%
encoding alibi iter 680: loss 2.2447%
encoding alibi iter 700: loss 2.2808%
encoding alibi iter 720: loss 2.2010%
encoding alibi iter 740: loss 2.2438%
encoding alibi iter 760: loss 2.2925%
encoding original iter 0: loss 4.1849%
encoding original iter 20: loss 3.5693%
encoding original iter 40: loss 3.0672%
encoding original iter 60: loss 2.6988%
encoding original iter 80: loss 2.6344%
encoding original iter 100: loss 2.5658%
encoding original iter 120: loss 2.6045%
encoding original iter 140: loss 2.5612%
encoding original iter 160: loss 2.5221%
encoding original iter 180: loss 2.4952%
encoding original iter 200: loss 2.4788%
encoding original iter 220: loss 2.5465%
encoding original iter 240: loss 2.4480%
encoding original iter 260: loss 2.4167%
encoding original iter 280: loss 2.4193%
encoding original iter 300: loss 2.3871%
encoding original iter 320: loss 2.4159%
encoding original iter 340: loss 2.3878%
encoding original iter 360: loss 2.3683%
encoding original iter 380: loss 2.3237%
encoding original iter 400: loss 2.3186%
encoding original iter 420: loss 2.3215%
encoding original iter 440: loss 2.2559%
encoding original iter 460: loss 2.3196%
encoding original iter 480: loss 2.3193%
encoding original iter 500: loss 2.3185%
encoding original iter 520: loss 2.1829%
encoding original iter 540: loss 2.2447%
encoding original iter 560: loss 2.2703%
encoding original iter 580: loss 2.2303%
encoding original iter 600: loss 2.1583%
encoding original iter 620: loss 2.1862%
encoding original iter 640: loss 2.1851%
encoding original iter 660: loss 2.1487%
encoding original iter 680: loss 2.1216%
encoding original iter 700: loss 2.1679%
encoding original iter 720: loss 2.0793%
encoding original iter 740: loss 2.1251%
encoding rope iter 0: loss 4.1894%
encoding rope iter 20: loss 3.5660%
encoding rope iter 40: loss 3.0054%
encoding rope iter 60: loss 2.7548%
encoding rope iter 80: loss 2.7000%
encoding rope iter 0: loss 4.1894%
encoding rope iter 20: loss 3.5660%
encoding rope iter 40: loss 3.0054%
encoding rope iter 60: loss 2.7548%
encoding rope iter 80: loss 2.7001%
encoding rope iter 100: loss 2.6335%
encoding rope iter 120: loss 2.5975%
encoding rope iter 140: loss 2.5645%
encoding rope iter 160: loss 2.5883%
encoding rope iter 180: loss 2.5872%
encoding rope iter 200: loss 2.4465%
encoding rope iter 220: loss 2.4729%
encoding rope iter 240: loss 2.4626%
encoding rope iter 0: loss 4.1894%
encoding rope iter 20: loss 3.5660%
encoding rope iter 40: loss 3.0054%
encoding rope iter 60: loss 2.7548%
encoding rope iter 80: loss 2.7000%
encoding rope iter 100: loss 2.6336%
encoding rope iter 120: loss 2.5975%
encoding rope iter 140: loss 2.5645%
encoding rope iter 160: loss 2.5883%
encoding rope iter 180: loss 2.5872%
encoding rope iter 200: loss 2.4466%
encoding rope iter 220: loss 2.4730%
encoding rope iter 240: loss 2.4625%
encoding rope iter 260: loss 2.4471%
encoding rope iter 280: loss 2.5434%
encoding rope iter 300: loss 2.4501%
encoding rope iter 320: loss 2.4831%
encoding rope iter 340: loss 2.5322%
encoding rope iter 360: loss 2.5365%
encoding rope iter 380: loss 2.4116%
encoding rope iter 400: loss 2.4621%
encoding rope iter 420: loss 2.4489%
encoding rope iter 440: loss 2.5184%
encoding rope iter 460: loss 2.3689%
encoding rope iter 0: loss 4.1775%
encoding rope iter 20: loss 3.5970%
encoding rope iter 40: loss 3.0234%
encoding rope iter 60: loss 2.7633%
encoding rope iter 80: loss 2.7058%
encoding rope iter 100: loss 2.6436%
encoding rope iter 120: loss 2.6045%
encoding rope iter 140: loss 2.5616%
encoding rope iter 160: loss 2.5846%
encoding rope iter 180: loss 2.5673%
encoding rope iter 200: loss 2.4448%
encoding rope iter 220: loss 2.4713%
encoding rope iter 240: loss 2.4453%
encoding rope iter 260: loss 2.4386%
encoding rope iter 280: loss 2.5531%
encoding rope iter 300: loss 2.4652%
encoding rope iter 320: loss 2.4764%
encoding rope iter 340: loss 2.5544%
encoding rope iter 360: loss 2.5307%
encoding rope iter 380: loss 2.4057%
encoding rope iter 400: loss 2.4563%
encoding rope iter 420: loss 2.4459%
encoding rope iter 440: loss 2.5306%
encoding rope iter 460: loss 2.3825%
encoding rope iter 480: loss 2.4837%
encoding rope iter 500: loss 2.4196%
encoding rope iter 520: loss 2.4573%
encoding rope iter 540: loss 2.4632%
encoding rope iter 560: loss 2.3652%
encoding rope iter 580: loss 2.3007%
encoding rope iter 600: loss 2.3529%
encoding rope iter 620: loss 2.3553%
encoding rope iter 640: loss 2.3209%
encoding rope iter 660: loss 2.3597%
encoding rope iter 680: loss 2.4467%
encoding rope iter 700: loss 2.3483%
encoding rope iter 720: loss 2.3325%
encoding rope iter 740: loss 2.2727%
encoding rope iter 760: loss 2.2435%
encoding rope iter 780: loss 2.3385%
encoding rope iter 800: loss 2.2269%
encoding rope iter 820: loss 2.2154%
encoding rope iter 840: loss 2.2282%
encoding rope iter 0: loss 4.1777%
encoding rope iter 20: loss 3.5970%
encoding rope iter 40: loss 3.0235%
encoding rope iter 60: loss 2.7619%
encoding rope iter 80: loss 2.6744%
encoding rope iter 100: loss 2.5464%
encoding rope iter 120: loss 2.4951%
encoding rope iter 140: loss 2.3928%
encoding rope iter 160: loss 2.3979%
encoding rope iter 180: loss 2.3598%
encoding rope iter 0: loss 4.1777%
encoding rope iter 20: loss 3.5970%
encoding rope iter 40: loss 3.0235%
encoding rope iter 60: loss 2.7619%
encoding rope iter 80: loss 2.6744%
encoding rope iter 100: loss 2.5464%
encoding rope iter 120: loss 2.4951%
encoding rope iter 140: loss 2.3928%
encoding rope iter 160: loss 2.3979%
encoding rope iter 180: loss 2.3598%
encoding rope iter 200: loss 2.2623%
encoding rope iter 220: loss 2.2407%
encoding rope iter 240: loss 2.1501%
encoding rope iter 0: loss 4.1777%
encoding rope iter 20: loss 3.5970%
encoding rope iter 40: loss 3.0235%
encoding rope iter 60: loss 2.7619%
encoding rope iter 80: loss 2.6744%
encoding rope iter 100: loss 2.5464%
encoding rope iter 120: loss 2.4951%
encoding rope iter 140: loss 2.3928%
encoding rope iter 160: loss 2.3979%
encoding rope iter 180: loss 2.3598%
encoding rope iter 200: loss 2.2623%
encoding rope iter 220: loss 2.2407%
encoding rope iter 240: loss 2.1501%
encoding rope iter 260: loss 2.1737%
encoding rope iter 280: loss 2.3099%
encoding rope iter 300: loss 2.1743%
encoding rope iter 320: loss 2.1709%
encoding rope iter 340: loss 2.1747%
encoding rope iter 360: loss 2.2210%
encoding rope iter 380: loss 2.0630%
encoding rope iter 400: loss 2.1908%
encoding rope iter 420: loss 2.0842%
encoding alibi iter 0: loss 4.1631%
encoding alibi iter 20: loss 3.4788%
encoding alibi iter 40: loss 2.9751%
encoding alibi iter 60: loss 2.7445%
encoding alibi iter 80: loss 2.6908%
encoding alibi iter 100: loss 2.6225%
encoding alibi iter 120: loss 2.5961%
encoding alibi iter 140: loss 2.5692%
encoding alibi iter 160: loss 2.5802%
encoding alibi iter 180: loss 2.6010%
encoding alibi iter 200: loss 2.4499%
encoding alibi iter 220: loss 2.4764%
encoding alibi iter 240: loss 2.4725%
encoding alibi iter 260: loss 2.4563%
encoding alibi iter 280: loss 2.5614%
encoding alibi iter 300: loss 2.4657%
encoding alibi iter 320: loss 2.5087%
encoding alibi iter 340: loss 2.5743%
encoding alibi iter 360: loss 2.5460%
encoding alibi iter 380: loss 2.4199%
encoding alibi iter 400: loss 2.4823%
encoding alibi iter 420: loss 2.4866%
encoding alibi iter 440: loss 2.5406%
encoding alibi iter 460: loss 2.4240%
encoding alibi iter 480: loss 2.5190%
encoding alibi iter 500: loss 2.4519%
encoding alibi iter 520: loss 2.5068%
encoding alibi iter 540: loss 2.4851%
encoding alibi iter 560: loss 2.4165%
encoding alibi iter 580: loss 2.3856%
encoding alibi iter 600: loss 2.4407%
encoding alibi iter 620: loss 2.4306%
encoding alibi iter 640: loss 2.4215%
encoding alibi iter 660: loss 2.4275%
encoding alibi iter 0: loss 4.1631%
encoding alibi iter 20: loss 3.4788%
encoding alibi iter 40: loss 2.9751%
encoding alibi iter 60: loss 2.7445%
encoding alibi iter 80: loss 2.6908%
encoding alibi iter 100: loss 2.6225%
encoding alibi iter 120: loss 2.5961%
encoding alibi iter 140: loss 2.5692%
encoding alibi iter 160: loss 2.5802%
encoding alibi iter 180: loss 2.6010%
encoding alibi iter 200: loss 2.4499%
encoding alibi iter 220: loss 2.4764%
encoding alibi iter 240: loss 2.4725%
encoding alibi iter 260: loss 2.4563%
encoding alibi iter 280: loss 2.5614%
encoding alibi iter 300: loss 2.4657%
encoding alibi iter 320: loss 2.5087%
encoding alibi iter 340: loss 2.5743%
encoding alibi iter 360: loss 2.5460%
encoding alibi iter 380: loss 2.4199%
encoding alibi iter 400: loss 2.4823%
encoding alibi iter 420: loss 2.4866%
encoding alibi iter 440: loss 2.5406%
encoding alibi iter 460: loss 2.4240%
encoding alibi iter 480: loss 2.5190%
encoding alibi iter 500: loss 2.4519%
encoding alibi iter 520: loss 2.5068%
encoding alibi iter 540: loss 2.4851%
encoding alibi iter 560: loss 2.4165%
encoding rope iter 0: loss 4.1777%
encoding rope iter 20: loss 3.5970%
encoding rope iter 40: loss 3.0235%
encoding rope iter 60: loss 2.7619%
encoding rope iter 80: loss 2.6744%
encoding rope iter 100: loss 2.5464%
encoding rope iter 120: loss 2.4951%
encoding rope iter 140: loss 2.3928%
encoding rope iter 160: loss 2.3979%
encoding rope iter 180: loss 2.3598%
encoding rope iter 200: loss 2.2623%
encoding rope iter 220: loss 2.2407%
encoding rope iter 240: loss 2.1501%
encoding rope iter 260: loss 2.1737%
encoding rope iter 280: loss 2.3099%
encoding rope iter 300: loss 2.1743%
encoding rope iter 320: loss 2.1709%
encoding rope iter 340: loss 2.1747%
encoding rope iter 360: loss 2.2210%
encoding rope iter 0: loss 4.1631%
encoding rope iter 20: loss 3.4763%
encoding rope iter 40: loss 2.9732%
encoding rope iter 60: loss 2.7386%
encoding rope iter 80: loss 2.6437%
encoding rope iter 100: loss 2.4945%
encoding rope iter 120: loss 2.4792%
encoding rope iter 140: loss 2.3722%
encoding rope iter 160: loss 2.3767%
encoding sinusoidal iter 0: loss 4.1921%
encoding sinusoidal iter 20: loss 3.8176%
encoding sinusoidal iter 40: loss 3.3213%
encoding sinusoidal iter 60: loss 3.2778%
encoding sinusoidal iter 80: loss 3.3752%
encoding sinusoidal iter 100: loss 3.3239%
encoding sinusoidal iter 120: loss 3.2565%
encoding sinusoidal iter 140: loss 3.4586%
encoding sinusoidal iter 160: loss 3.2336%
encoding sinusoidal iter 180: loss 3.3821%
encoding sinusoidal iter 200: loss 3.3035%
encoding sinusoidal iter 220: loss 3.2418%
encoding sinusoidal iter 240: loss 3.3708%
encoding sinusoidal iter 260: loss 3.3530%
encoding sinusoidal iter 280: loss 3.4167%
encoding sinusoidal iter 300: loss 3.3632%
encoding sinusoidal iter 320: loss 3.3364%
encoding sinusoidal iter 340: loss 3.3772%
encoding sinusoidal iter 360: loss 3.5428%
encoding sinusoidal iter 380: loss 3.1713%
encoding sinusoidal iter 400: loss 3.1450%
encoding sinusoidal iter 420: loss 3.2072%
encoding sinusoidal iter 440: loss 3.0187%
encoding sinusoidal iter 460: loss 2.9536%
encoding sinusoidal iter 480: loss 2.9238%
encoding sinusoidal iter 500: loss 2.9172%
encoding sinusoidal iter 520: loss 2.8548%
encoding sinusoidal iter 540: loss 2.8406%
encoding sinusoidal iter 560: loss 2.8380%
encoding sinusoidal iter 580: loss 2.7880%
encoding sinusoidal iter 600: loss 2.8535%
encoding sinusoidal iter 620: loss 2.7658%
encoding sinusoidal iter 640: loss 2.8709%
encoding sinusoidal iter 660: loss 2.7667%
encoding sinusoidal iter 680: loss 2.9342%
encoding sinusoidal iter 700: loss 2.7801%
encoding sinusoidal iter 720: loss 2.7322%
encoding sinusoidal iter 740: loss 2.7225%
encoding sinusoidal iter 760: loss 2.6643%
encoding sinusoidal iter 0: loss 4.1921%
encoding sinusoidal iter 20: loss 3.8176%
encoding sinusoidal iter 40: loss 3.3213%
encoding sinusoidal iter 60: loss 3.2778%
encoding sinusoidal iter 80: loss 3.3752%
encoding sinusoidal iter 100: loss 3.3239%
encoding sinusoidal iter 120: loss 3.2565%
encoding sinusoidal iter 140: loss 3.4586%
encoding sinusoidal iter 160: loss 3.2336%
encoding sinusoidal iter 180: loss 3.3821%
encoding sinusoidal iter 200: loss 3.3035%
encoding sinusoidal iter 220: loss 3.2418%
encoding sinusoidal iter 240: loss 3.3708%
